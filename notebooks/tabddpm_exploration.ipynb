{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a13c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15cca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1      V2    V3   V4     V5    V6     V7   V8   V9   V10 Class\n",
       "0  65.0  Female   0.7  0.1  187.0  16.0   18.0  6.8  3.3  0.90     1\n",
       "1  62.0    Male  10.9  5.5  699.0  64.0  100.0  7.5  3.2  0.74     1\n",
       "2  62.0    Male   7.3  4.1  490.0  60.0   68.0  7.0  3.3  0.89     1\n",
       "3  58.0    Male   1.0  0.4  182.0  14.0   20.0  6.8  3.4  1.00     1\n",
       "4  72.0    Male   3.9  2.0  195.0  27.0   59.0  7.3  2.4  0.40     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/raw/phpOJxGL9.arff'\n",
    "\n",
    "data, meta = arff.loadarff(file_path)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7fcadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[['V1', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970579be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, categorical_cols=None, test_size=0.2):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Detect numeric and categorical\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_cols = df.columns.difference(categorical_cols).tolist()\n",
    "\n",
    "    # Encode categorical\n",
    "    encoder = OrdinalEncoder()\n",
    "    df[categorical_cols] = encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "    # Scale numerical\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Convert to torch\n",
    "    X = torch.tensor(df.values, dtype=torch.float32)\n",
    "\n",
    "    X_train, X_val = train_test_split(X, test_size=test_size, random_state=42)\n",
    "    train_loader = DataLoader(TensorDataset(X_train), batch_size=256, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val), batch_size=256)\n",
    "\n",
    "    return train_loader, val_loader, len(numerical_cols), [int(df[col].nunique()) for col in categorical_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from src.tabddpm.modules import timestep_embedding, MLP\n",
    "\n",
    "class MLPDiffusion(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified MLP-based diffusion model for tabular data.\n",
    "\n",
    "    This model uses timestep embeddings and a projection layer\n",
    "    to inject time information into the input before processing it\n",
    "    through an MLP. It is intended for unsupervised tasks like clustering,\n",
    "    where label conditioning is not required.\n",
    "\n",
    "    Args:\n",
    "        d_in (int): Input feature dimension.\n",
    "        rtdl_params (dict): Parameters for the RTDL MLP (e.g., hidden sizes, depth).\n",
    "        dim_t (int): Dimensionality for the timestep embedding and projection space.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in, rtdl_params, dim_t=128):\n",
    "        super().__init__()\n",
    "        self.dim_t = dim_t\n",
    "\n",
    "        # Configure MLP: input will be timestep-embedded, output must match original input size\n",
    "        rtdl_params['d_in'] = dim_t\n",
    "        rtdl_params['d_out'] = d_in\n",
    "        self.mlp = MLP.make_baseline(**rtdl_params)\n",
    "\n",
    "        # Project input features into timestep embedding space\n",
    "        self.proj = nn.Linear(d_in, dim_t)\n",
    "\n",
    "        # Timestep embedding network (2-layer MLP with SiLU activation)\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(dim_t, dim_t),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim_t, dim_t)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, timesteps):\n",
    "        \"\"\"\n",
    "        Forward pass of the MLPDiffusion model.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, d_in).\n",
    "            timesteps (Tensor): Timestep tensor of shape (batch_size,) representing the diffusion step.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor of shape (batch_size, d_in), same as the input dimension.\n",
    "        \"\"\"\n",
    "        # Get timestep embedding (e.g., sinusoidal), then pass through a small MLP\n",
    "        emb = self.time_embed(timestep_embedding(timesteps, self.dim_t))\n",
    "\n",
    "        # Project input to timestep embedding space and add time information\n",
    "        x = self.proj(x) + emb\n",
    "\n",
    "        # Pass through MLP and return\n",
    "        return self.mlp(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7af97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tabddpm.gaussian_multinomial_diffusion import GaussianMultinomialDiffusion\n",
    "\n",
    "def get_diffusion_model(model, num_classes, num_numerical, device):\n",
    "    diffusion = GaussianMultinomialDiffusion(\n",
    "        num_classes=np.array(num_classes),\n",
    "        num_numerical_features=num_numerical,\n",
    "        denoise_fn=model,\n",
    "        gaussian_loss_type='mse',\n",
    "        num_timesteps=1000,\n",
    "        scheduler='cosine',\n",
    "        device=device\n",
    "    )\n",
    "    diffusion.to(device)\n",
    "    return diffusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, steps=1000, lr=1e-3, device='cuda'):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.steps = steps\n",
    "        self.device = device\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "        self.ema_model = deepcopy(model._denoise_fn)\n",
    "        for p in self.ema_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def train(self):\n",
    "        step = 0\n",
    "        iterator = iter(self.train_loader)\n",
    "\n",
    "        while step < self.steps:\n",
    "            try:\n",
    "                x_batch, = next(iterator)\n",
    "            except StopIteration:\n",
    "                iterator = iter(self.train_loader)\n",
    "                x_batch, = next(iterator)\n",
    "\n",
    "            x_batch = x_batch.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_multi, loss_gauss = self.model.mixed_loss(x_batch, {})\n",
    "            loss = loss_multi + loss_gauss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[{step}/{self.steps}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "            step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c24096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000] Loss: 2.1671\n",
      "[100/1000] Loss: 2.4032\n",
      "[200/1000] Loss: 1.2397\n",
      "[300/1000] Loss: 1.3275\n",
      "[400/1000] Loss: 0.8968\n",
      "[500/1000] Loss: 0.9164\n",
      "[600/1000] Loss: 0.8772\n",
      "[700/1000] Loss: 0.9224\n",
      "[800/1000] Loss: 1.0575\n",
      "[900/1000] Loss: 0.7988\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader, _, num_numerical, num_classes = prepare_dataset(df_train, ['V2'])\n",
    "\n",
    "model_params = {\n",
    "    'num_classes': 0,\n",
    "    'is_y_cond': False,\n",
    "    'rtdl_params': {\n",
    "        'd_layers': [256, 256, 256],\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "mlp_model = MLPDiffusion(\n",
    "    d_in=df.shape[1],\n",
    "    num_classes=model_params['num_classes'],\n",
    "    is_y_cond=model_params['is_y_cond'],\n",
    "    rtdl_params=model_params['rtdl_params']\n",
    ")\n",
    "\n",
    "mlp_model.to(device)\n",
    "\n",
    "diffusion = get_diffusion_model(mlp_model, num_classes, num_numerical, device)\n",
    "\n",
    "trainer = Trainer(diffusion, train_loader, steps=1000, device=device)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78a438f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GaussianMultinomialDiffusion.sample_time() got an unexpected keyword argument 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_time\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muniform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: GaussianMultinomialDiffusion.sample_time() got an unexpected keyword argument 'y'"
     ]
    }
   ],
   "source": [
    "diffusion.sample_time(2, device, 'uniform', **{'y':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95485030",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m100\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 3. Add noise to x_orig using the diffusion's q_sample\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 4. Reconstruct using the model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m recon \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mp_sample(x_noisy, t, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\UniWien\\MT\\CluTaD\\src\\tabddpm\\gaussian_multinomial_diffusion.py:474\u001b[0m, in \u001b[0;36mGaussianMultinomialDiffusion.q_sample\u001b[1;34m(self, log_x_start, t)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mq_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, log_x_start, t):\n\u001b[1;32m--> 474\u001b[0m     log_EV_qxt_x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_x_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     log_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_sample_categorical(log_EV_qxt_x0)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_sample\n",
      "File \u001b[1;32mc:\\Users\\bokovacs\\OneDrive - WU Wien\\Dokumente\\Learning\\UniWien\\MT\\CluTaD\\src\\tabddpm\\gaussian_multinomial_diffusion.py:364\u001b[0m, in \u001b[0;36mGaussianMultinomialDiffusion.q_pred\u001b[1;34m(self, log_x_start, t)\u001b[0m\n\u001b[0;32m    359\u001b[0m log_cumprod_alpha_t \u001b[38;5;241m=\u001b[39m extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_cumprod_alpha, t, log_x_start\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    360\u001b[0m log_1_min_cumprod_alpha \u001b[38;5;241m=\u001b[39m extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_1_min_cumprod_alpha, t, log_x_start\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    362\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m log_add_exp(\n\u001b[0;32m    363\u001b[0m     log_x_start \u001b[38;5;241m+\u001b[39m log_cumprod_alpha_t,\n\u001b[1;32m--> 364\u001b[0m     \u001b[43mlog_1_min_cumprod_alpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes_expanded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m )\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_probs\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# 1. Select an input sample x\n",
    "x_orig = next(iter(train_loader))[0].to(device)[:1]  # single sample\n",
    "\n",
    "# 2. Pick a timestep (e.g., t = 100)\n",
    "t = torch.tensor([100], device=device)\n",
    "\n",
    "# 3. Add noise to x_orig using the diffusion's q_sample\n",
    "x_noisy = diffusion.q_sample(x_orig, t)\n",
    "\n",
    "# 4. Reconstruct using the model\n",
    "recon = diffusion.p_sample(x_noisy, t, y=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba80281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6025,  3.7074,  3.7825, -0.7522,  0.4784,  1.8017,  2.5051, -1.4366,\n",
       "         -2.0334,  1.0000]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
